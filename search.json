[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Jul 26, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#statistics-and-data-analysis",
    "href": "index.html#statistics-and-data-analysis",
    "title": "Tutorials",
    "section": "Statistics and Data Analysis",
    "text": "Statistics and Data Analysis\n\n\n\n\n\n\n\n\n\n\nOrder Statistics\n\n\n\nSep 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantile-Quantile Plots\n\n\n\nSep 20, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#miscellaneous",
    "href": "index.html#miscellaneous",
    "title": "Tutorials",
    "section": "Miscellaneous",
    "text": "Miscellaneous\n\n\n\n\n\n\n\n\n\n\nLorenz System\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "topology/smith/index.html",
    "href": "topology/smith/index.html",
    "title": "Smith Normal Form",
    "section": "",
    "text": "Matrix reduction plays a fundamental role in the study of vector spaces and linear transformations. Reduction of a matrix to a canonical or normal form finds its use in almost all applied fields of science. While there are many different normal forms a matrix can be reduced to, a normal form is usually the product of much simpler and well-understood (e.g., diagonal, upper/lower triangular, etc) matrices. Since, the reduction process faithfully carries most of the nice properties of the original matrix, one can use a normal form to infer some of those properties from matrices with relatively simple structure.\nThe choice of the normal form can sometimes be demanded by a particular application, or be limited by the algebraic operations one is allowed to perform on the entries of the original matrix. Today we consider, for reduction, only \\(\\mathbb Z\\)-matrices, i.e., matrices that are allowed to have only integer entries. As a consequence, the only permitted operations on the entries of such a matrix are addition and multiplication—but not division. We denote by \\(\\mathcal{M}_{n,m}(\\mathbb Z)\\) the set of all integer matrices with \\(n\\) rows and \\(m\\) columns. In the special case of square matrices (\\(m=n\\)), we simply call it \\(\\mathcal{M}_{m}(\\mathbb Z)\\) or \\(\\mathcal{M}_{n}(\\mathbb Z)\\). Note that the identity matrix, \\(I_{m}\\), of dimension \\(m\\) is a \\(\\mathbb Z\\)-matrix, i.e., \\(I_m\\in\\mathcal{M}_{m}(\\mathbb Z)\\).\n\n\nAlthough our hands are now tied by the restriction on the operations allowed on a matrix \\(A\\in\\mathcal{M}_{n,m}(\\mathbb Z)\\), we can still follow the usual definitions of matrix addition, subtraction, and multiplication— also determinant and inverse of a square matrix. For a square matrix \\(A\\in\\mathcal{M}_{n}(\\mathbb Z)\\), its determinant is defined the usual way. Also, \\(A\\) is said to have an inverse \\(B\\in\\mathcal{M}_{n}(\\mathbb Z)\\) if \\(AB=BA=I_n\\). The set of all invertible (square) matrices of dimension \\(n\\) is denoted by \\(GL_{n}(\\mathbb Z)\\).\n\n\n\nGiven an \\(A\\in\\mathcal{M}_{n,m}(\\mathbb Z)\\), we seek invertible matrices \\(P\\in GL_{m}(\\mathbb Z)\\) and \\(Q\\in GL_{n}(\\mathbb Z)\\) such that \\(D=Q^{-1}AP,\\) where \\(D\\) is an \\(n\\times m\\) diagonal integer matrix: \\[\n\\newcommand\\bigzero{\\makebox(0,0){\\text{\\huge0}}}\n\\begin{pmatrix}\n\\begin{array}{c:c}\n  \\begin{matrix}\n    d_1 & 0 & \\ldots & 0 \\\\\n    0 & d_2 & \\ldots & 0\\\\\n    0 & \\ldots & \\ldots & 0 \\\\\n    0 & \\ldots & 0 & d_k \\\\\n  \\end{matrix}\n  & {\\huge0}_{k,m-k} \\\\\n  \\hdashline \\\\\n  {\\huge0}_{n-k,k} & {\\huge0}_{n-k,m-k}\n\\end{array}\n\\end{pmatrix}\n\\] with \\(d_i\\geq0\\) for all \\(i=1, 2, \\ldots, k\\) and \\(d_1| d_2| \\ldots | d_k\\).\nNote: - the diagonal matrix \\(D\\) always exists, as we allow it to be a zero matrix; it is also unique. - \\(P,Q\\) may not, however, be unique [artin]. - if \\(A\\) is viewed as the matrix of a linear transformation \\(T:G_1\\to G_2\\) between two finitely-generated free abelian groups, then \\(P\\) and \\(Q\\) are the basechange matrices for \\(G_1\\) and \\(G_2\\), respectively.\n\n\n\nUnlike the other popular canonical forms—e.g., the Jordan normal form for matrices over an algebraically-closed field—the Smith normal form is particularly relevant in the context of \\(\\mathbb Z\\)-modules, more generally \\(R\\)-modules [artin]. In the field of combinatorial topology, the reduction to Smith normal form facilitates the computation of the homology groups of finte simplicial complexes [Munkres84]."
  },
  {
    "objectID": "topology/smith/index.html#elementary-operations",
    "href": "topology/smith/index.html#elementary-operations",
    "title": "Smith Normal Form",
    "section": "Elementary Operations",
    "text": "Elementary Operations\nAs stated above without a proof that the reduction of an integer matrix to a Smith normal form always exists. We now present the steps one can perform to decompose a given matrix. The basis of the reduction process involves three elementary operations. We invoke them repeatedly on the original matrix in the right order. We are going to use three elementary row operations and three corresonding column operations.\n\nElementary Matrices\nEach of the following row (and column) operations can also be described as pre (and post) multiplication by an elementary matrix. For each elementary operation, there is an associated elementary matrix, which is obtained by performing the same operation on the identity matrix of the right size.\n\n\nRow Operations\nWe first define and then demonstrate the elementary row operations. The outcome \\(A'\\) of each row operation on \\(A\\) is a pre-multiplication of \\(A\\) by an elementary matrix \\(E\\), i.e., \\(A'=EA\\). The three types of row operations are as follows:\n\nMultiply the \\(i\\)-th row by \\(-1\\)\nExchange the \\(i\\)-th and \\(j\\)-th row\nReplace the \\(i\\)-th row with the row plus \\(q\\) times the \\(j\\)-th row (\\(i\\neq j, q\\neq 0\\))\n\n\n\nColumn Operations\nThe outcome \\(A'\\) of each column operation on \\(A\\) is post-multiplication of \\(A\\) by an elementary matrix \\(E\\), i.e., \\(A'=AE\\). The three types of column operations are as follows:\n\nMultiply the \\(i\\)-th column by \\(-1\\)\nExchange the \\(i\\)-th and \\(j\\)-th column\nReplace \\(i\\)-th column with the column plus \\(q\\) times the \\(j\\)-th column (\\(i\\neq j, q\\neq 0\\))\n\n\n\nDemo\nThe operations are best understood when demonstrated on an example matrix. To that end, we first generate a random matrix \\(A\\) with integer (between \\(-5\\) and \\(5\\)) entries by choosing the number of rows and columns using the sliders.\n\n\nCode\nviewof m = Inputs.range([1, 6], {\n  value: 5,\n  step: 1,\n  label: \"Number of rows (n):\"\n})\nviewof n = Inputs.range([1, 6], {\n  value: 4,\n  step: 1,\n  label: \"Number of cols (m):\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you do not like the random matrix, try fiddling with the above sliders to generate a new one!\n\n\nCode\ntex.block`A=${nj.mat2Tex(A)}`\n\n\n\n\n\n\n\nSee for yourself: From the dropdown below choose the operation type (row/column) and an operation. Also, set the values of the arguemts for the operations chosen, using the sliders.\n\n\nCode\nviewof opType = Inputs.select([\"row\", \"col\"], {\n  label: \"Type of operation\"\n})\nviewof operation = Inputs.select(\n  Operations[opType].map((o) => o.name),\n  {\n    label: \"operation\"\n  }\n)\nviewof i = Inputs.range([1, opType === \"row\" ? n : m], {\n  value: 1,\n  step: 1,\n  label: tex`i`\n})\nviewof j = Inputs.range([1, opType === \"row\" ? n : m], {\n  value: 2,\n  step: 1,\n  label: tex`j`\n})\nviewof q = Inputs.range([-20, 20], {\n  value: 10,\n  step: 1,\n  label: tex`q`\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere is the outcome matrix:\n\n\nCode\ntex.block`A'=${nj.mat2Tex(Result[0])}`\n\n\n\n\n\n\n\nThe corresponding elementary matrix \\(E\\) is such that\n\n\nCode\nopType === 'row' ? tex`A'=EA` : tex`A'=AE.`\n\n\n\n\n\n\n\nAs will be discussed later, we accumulate the \\(E^{-1}\\) from the operations to compute the basechange matrix.\n\n\nCode\ntex.block`E=${nj.mat2Tex(Result[1])}\\text{, and }E^{-1}=${nj.mat2Tex(Result[2])}`\n\n\n\n\n\n\n\nWith all the background definitions and notations at our disposal to present the reduction algorithm."
  },
  {
    "objectID": "topology/smith/index.html#the-reduction-algorithm",
    "href": "topology/smith/index.html#the-reduction-algorithm",
    "title": "Smith Normal Form",
    "section": "The Reduction Algorithm",
    "text": "The Reduction Algorithm\nBefore we discuss the algorithm in detail, feel free to take a quick detour to see the reduction in action!\nGiven an integer matrix \\(A\\) of any size, its reduction to the Smith normal form follows three major steps:\n\nStep 0: Set the offset\nThe algorithm relies on an offset parameter. Starting with offset=\\(1\\), the reduction process works on the original matrix, inductively, by incrementing the offset. The offset determines how much of the matrix has been already been processed; it ranges from \\(1\\) to \\(\\min\\{n,m\\}\\). When the function reduce(offset) is called, it assumes that the offset-block, block with the diagonal element (offset,offset) at its top-left corner, has to be processed, and all other rows and columns are already in good shape.\nTo get an idea of how offset plays its role, try choosing an offset from the slider. If the reduction algorithm is called it would assume that the green elements are already processed, and the (gray) offset-block is yet to be processed.\n\n\nCode\nviewof offset = Inputs.range([1, Math.min(n, m)], {\n  value: 1,\n  step: 1,\n  label: `offset`\n})\n\n\n\n\n\n\n\n\n\nCode\n{\n  const container = d3.create(\"div\").attr(\"class\", \"mat-container\");\n\n  container\n    .selectAll(\".row\")\n    .data(A)\n    .join(\"div\")\n    .attr(\"class\", \"row\")\n    .selectAll(\"div\")\n    .data((d) => d)\n    .join(\"div\")\n    .attr(\"class\", \"element\")\n    .text((d) => d);\n\n  container\n    .selectAll(\".row\")\n    .filter((d, k) => k < offset - 1)\n    .selectAll(\".element\")\n    .style(\"background\", \"#BDF3C2\");\n  container\n    .selectAll(\".row\")\n    .selectAll(\".element\")\n    .filter((d, k) => k < offset - 1)\n    .style(\"background\", \"#BDF3C2\");\n  yield container.node();\n}\n\n\n\n\n\n\n\nA Word of Caution: Note, however, that the green rows and columns may not be yet processed in the following demo matrix.\n\n\nStep 1: Find the Best Pivot\nFor a given offset, we find the best pivot: a (non-zero) element that divides all other elements of the offset-block. This step involves finding repeatedly a pivot, then improving it.\nStep 1.1 Find a Pivot and antiPivot:\nFor a given offset-block, a pivot is a non-zero element with the smallest absolute value; shown with a green border below.\nIf the pivot-block is has all zero entries, we return the step. If not, a pivot can be found in \\(O(mn)\\)-time.\n\n\nCode\n{\n  const container = d3.create(\"div\").attr(\"class\", \"mat-container\");\n\n  container\n    .selectAll(\".row\")\n    .data(A)\n    .join(\"div\")\n    .attr(\"class\", \"row\")\n    .selectAll(\"div\")\n    .data((d) => d)\n    .join(\"div\")\n    .attr(\"class\", \"element\")\n    .text((d) => d);\n\n  container\n    .selectAll(\".row\")\n    .filter((d, k) => k < offset - 1)\n    .selectAll(\".element\")\n    .style(\"background\", \"#BDF3C2\");\n  container\n    .selectAll(\".row\")\n    .selectAll(\".element\")\n    .filter((d, k) => k < offset - 1)\n    .style(\"background\", \"#BDF3C2\");\n\n  container\n    .selectAll(\".row\")\n    .filter((d, k) => k === pivot[0])\n    .selectAll(\".element\")\n    .filter((d, k) => k === pivot[1])\n    .style(\"border\", \"2px solid green\");\n\n  container\n    .selectAll(\".row\")\n    .filter((d, k) => k === antiPivot[0])\n    .selectAll(\".element\")\n    .filter((d, k) => k === antiPivot[1])\n    .style(\"border\", \"2px solid red\");\n  yield container.node();\n}\n\n\n\n\n\n\n\nWe say that pivot can still be improved if, in the offset-block, there is an antiPivot: an element that does not divisible by the current pivot. In the demo, an antiPivot of a pivot is shown with a red border.\nIf antiPivot does not exist, we skip Step 1.1. Otherwise, we improve the pivot.\nStep 1.2 Improve the Pivot\n\n\nCode\n{\n  if (antiPivot.length === 0)\n    return md`For the offset-block, we see that the pivot is already the best. So, we skip this step.`;\n  else\n    return md`For the offset-block, we see that the antiPivot exists. So, we take this step.`;\n}\n\n\n\n\n\n\n\nLet \\([i,j]\\) and \\([s,t]\\) be the positions of pivot and antiPivot.\nCase I (\\(i=s\\)): If the pivot and antiPivot are on the same row, replace the antiPivot column by \\(q \\times\\) the pivot column, where \\(a_{it}= qa_{ij}+r\\) with \\(0<r<a_{ij}\\). As a result, \\(a_{it}\\) becomes \\(r\\) after the operations, and \\(a_{ij}\\) fails to to the pivot for the output offset-block.\nCase II (\\(j=t\\)): same operation as in Case I, but for rows.\nCase III (\\(i\\neq s, j\\neq t\\)): We assume for this case that \\(a_{ij}\\) divides all entries (of the current offset-block) in its row and column. If not, we are back to Case I.\nUsing this assumption we can replace the antiPivot row by  the pivot row, where \\(q=\\frac{a_{sj}}{a_{ij}}\\). After the operation, \\(a_{sj}\\) becomes zero. If we now add replace the \\(i\\)-th row by adding it to the \\(s\\)-th row, \\(a_{ij}\\) does not change, however the \\((i,t)\\)-th becomes \\(a_{it}+a_{st}\\), which is not divisible by \\(a_{ij}\\), and we are back to Case I.\nEach of the above cases yields a smaller pivot. We go back to Step 1.2 until the best pivot is found.\n\n\nStep 2: Move Pivot\nOnce the pivot is improved, we move the pivot to the top-left corner of the offset block by at most two elementary operations involving exchanging rows / columns.\n\n\nStep 3: Diagonalize\nSince the pivot divides all other elements in the offset block, one can find the right multiplier \\(q\\) for each row below and each column to its right to make entries zero by a series of operations involving replacing rows and columns.\nWe then increment the offset, and move to step 1.\nResult:\n\n\nCode\ntex`D=${nj.mat2Tex(NF.D)}`\n\n\n\n\n\n\n\n\n\nCode\ntex.block`\nQ^{-1}=${nj.mat2Tex(NF.Qinv)}\\text{, and }\nP=${nj.mat2Tex(NF.P)}\n`\n\n\n\n\n\n\n\nOne can check that ."
  },
  {
    "objectID": "topology/smith/index.html#change-of-bases",
    "href": "topology/smith/index.html#change-of-bases",
    "title": "Smith Normal Form",
    "section": "Change of Bases",
    "text": "Change of Bases\nAs we know now, the algorithm works by pre or post multiplying the original matrix \\(A\\) by an elementary matrix at each step of the reduction. Let \\(E_1,E_2,\\ldots,E_k\\) and \\(F_1,F_2,\\ldots,F_l\\) be the elementary matrices corresponding to the row and column operations performed in the increaing order of the subscript. Then the final diagonal matrix \\(D\\) can be written as: \\[D=E_k\\ldots E_2.E_1.A.F_1.F_2\\ldots F_l=Q^{-1}AP,\\] where \\(P=F_1.F_2\\ldots F_l\\) and \\(Q^{-1}=E_k\\ldots E_2.E_1\\).\nWe note that \\(P\\) and \\(Q=E_1^{-1}E_2^{-1}\\ldots E_k^{-1}\\) are the basechange matrices for \\(\\mathbb Z^m\\) (domain) and \\(\\mathbb Z^n\\) (co-domain), respectively.\n\n\nCode\ntex.block`\n\\mathcal{B}=${nj.vec2Tex(B)}\\text{, and }\n\\mathcal{B'}=${nj.vec2Tex(B1)}\n`\n\n\n\n\n\n\n\nLet \\(\\mathcal{C},\\mathcal{C}'\\) be the new bases. We compute:\n\n\nCode\ntex`\\mathcal{C}=${nj.vec2Tex(nj.changeBasis(B, NF.P))}`\n\n\n\n\n\n\n\n\n\nCode\ntex`\\mathcal{C}'=${nj.vec2Tex(nj.changeBasis(B1, NF.Q))}`"
  },
  {
    "objectID": "topology/smith/index.html#discussion",
    "href": "topology/smith/index.html#discussion",
    "title": "Smith Normal Form",
    "section": "Discussion",
    "text": "Discussion\nIf you are too excited to explore more on the subject, the reader is advised to call on [artin]. The examples in this tutorial are produced using codes from the JS package: @tdajs/normal-form. Visit the Github repo for more information. Happy coding!\n\n\nCode\nnj = require(\"https://bundle.run/@tdajs/normal-form@2.0.0\")\nA = {\n  let rows = n; //d3.randomInt(1, 10)();\n  let cols = m; //d3.randomInt(1, 10)();\n\n  return d3.range(0, rows).map((row) => {\n    return d3.range(0, cols).map((elm) => d3.randomInt(-5, 5)());\n  });\n}\nOperations = {\n  const obj = {\n    row: [\n      { name: \"exchangeRows\", args: [\"i\", \"j\"] },\n      { name: \"replaceRow\", args: [\"i\", \"j\", \"q\"] },\n      { name: \"multiplyRow\", args: [\"i\"] }\n    ],\n    col: [\n      { name: \"exchangeCols\", args: [\"i\", \"j\"] },\n      { name: \"replaceCol\", args: [\"i\", \"j\", \"q\"] },\n      { name: \"multiplyCol\", args: [\"i\"] }\n    ]\n  };\n  return obj;\n}\npivot = nj.findPivot(A, offset - 1)\nantiPivot = nj.findAntiPivot(pivot, A, offset - 1)\nResult = {\n  if (operation.includes(\"exchange\"))\n    return nj[operation](i - 1, j - 1, A, { copy: true });\n  else if (operation.includes(\"multiply\"))\n    return nj[operation](i - 1, q, A, { copy: true });\n  else return nj[operation](i - 1, j - 1, q, A, { copy: true });\n}\n\nNF = new nj.NormalForm(A)\nB = Array.from({ length: m }).map((e, i) => \"e_\" + i)\nB1 = Array.from({ length: n }).map((e, i) => \"e_\" + i + \"'\")"
  },
  {
    "objectID": "topology/rips.html",
    "href": "topology/rips.html",
    "title": "Vietoris–Rips Complex",
    "section": "",
    "text": "Definition\nGiven a metric space \\((M,d_M)\\) and a scale \\(\\epsilon>0\\), the Vietoris-Rips complex \\(R_{\\epsilon}(M)\\) is a simplicial complex such that \\(\\sigma=\\{x_1,x_2,\\ldots,x_n\\}\\in R_\\epsilon(M)\\) if and only if \\(\\{x_1,x_2,\\ldots,x_n\\}\\subseteq M\\) with \\(diam(\\sigma)\\leq\\epsilon\\).\n\n\nDemo\nWe run a little JavaScript demo of Vietoris-Rips complex for a finite subset \\(V\\) under the Euclidean distance. Although the computed Rips complex is an abstract simplicial complex (without an embedding), we only show its shadow; see [2] for a definition.\n\ntex`\\epsilon=${scale}`\n\n\n\n\n\n\nAs we can see, the set \\(V\\) is currently empty, and the scale \\(\\epsilon\\) is set to zero. We pick a set of points in the plain by clicking on the canvas below. A word of caution: picking more than 30 points can substantially slow down your browser!\n\nV = [];\n\n\n\n\n\n\n\n{\n  const height = \"300px\";\n  const container = d3.create(\"div\").style(\"position\", \"relative\");\n  let svg = container\n    .append(\"svg\")\n    .attr(\"class\", \"canvas\")\n    .style(\"margin-left\", \"15px\")\n    .style(\"width\", \"90%\")\n    .style(\"height\", height)\n    .style(\"border\", \"0.5px solid #eee\");\n  \n  const triangles = svg.append(\"g\").attr(\"class\", \"triangles\");\n  const edges = svg.append(\"g\").attr(\"class\", \"edges\");\n  const vertices = svg.append(\"g\").attr(\"class\", \"vertices\");\n\n  // scale\n  container\n    .append(\"div\")\n    .style(\"width\", \"15px\")\n    .style(\"height\", height)\n    .style(\"background\", \"#eee\")\n    .style(\"position\", \"absolute\")\n    .style(\"top\", \"0\")\n    .style(\"bottom\", \"0\")\n    .append(\"div\")\n    .style(\"width\", \"100%\")\n    .style(\"height\", scale + \"px\")\n    .style(\"background\", \"steelblue\");\n  container\n    .append(\"div\")\n    .style(\"margin-left\", \"3px\")\n    .style(\"width\", height)\n    .style(\"display\", \"inline-block\")\n    .style(\"text-align\", \"center\")\n    .style(\"transform\", \"rotate(-90deg)\")\n    .style(\"transform-origin\", \"top left\")\n    .html(tex`\\epsilon`.outerHTML);\n\n  drawRips(svg, sc.rips(V, scale, 2));\n\n  svg.on(\"click\", (e) => {\n    const coord = d3.pointer(e);\n    V.push(coord);\n    drawRips(svg, sc.rips(V, scale, 2));\n  });\n  return container.node();\n}\n\n\n\n\n\n\nWe now use the slider to set the scale \\(\\epsilon\\):\n\nviewof scale = Inputs.range([0, 300], {\n  step: 1,\n  value: 0,\n  label: tex`\\epsilon`\n})\n\n\n\n\n\n\n\nviewof btn = Inputs.button(\"clear\", {\n  value: null,\n  reduce: () => { V.length = 0; viewof scale.value = 0;viewof scale.dispatchEvent(new CustomEvent(\"input\")); }\n})\n\n\n\n\n\n\nAs we add more points or fiddle with the scale, the Betti numbers of the computed Vietoris-Rips complex can also be computed.\n\nimport { slider } from \"@jashkenas/inputs\"\n\n\n\n\n\n\n\nsc = require(\"https://cdn.jsdelivr.net/npm/@tdajs/simplicial-complex@1.2.1/dist/min.js\")\n\n\n\n\n\n\n\ndrawRips = function (svg, rips) {\n  if (rips.simplices[2]) {\n    svg.selectAll(\".triangle\")\n      .data(rips.simplices[2])\n      .join(\"path\")\n      .attr(\"class\", \"triangle\")\n      .attr(\"d\", (d) => d3.line()(d.map((v) => V[v])))\n      .attr(\"fill\", \"lightgreen\")\n      .attr(\"stroke\", \"none\")\n      .attr(\"opacity\", \"0.5\");\n  }\n  if (rips.simplices[1]) {\n    svg.selectAll(\".edge\")\n      .data(rips.simplices[1])\n      .join(\"path\")\n      .attr(\"class\", \"edge\")\n      .attr(\"d\", (d) => d3.line()(d.map((v) => V[v])))\n      .attr(\"stroke\", \"red\");\n  }\n\n  svg.selectAll(\".vertex\")\n    .data(V)\n    .join(\"circle\")\n    .attr(\"class\", \"vertex\")\n    .attr(\"class\", \"vertex\")\n    .attr(\"cx\", (d) => d[0])\n    .attr(\"cy\", (d) => d[1])\n    .attr(\"r\", \"2px\")\n    .on(\"mouseover\", function () {\n      d3.select(this).attr(\"fill\", \"orange\").attr(\"r\", \"5px\");\n    })\n    .on(\"mouseout\", function () {\n      d3.select(this).attr(\"fill\", \"black\").attr(\"r\", \"2px\");\n    });\n    return svg;\n}"
  },
  {
    "objectID": "topology/abelian-groups/index.html",
    "href": "topology/abelian-groups/index.html",
    "title": "Finitely-Generated Free Abelian Groups",
    "section": "",
    "text": "Let \\((G,+)\\) and \\((G',+)\\) be finitely-generated free (additive) abelian groups of dimension \\(m\\) and \\(n\\), respectively. We choose arbitrary ordered bases \\(\\mathcal{E}=(e_1,e_2,\\ldots,e_m)\\) and \\(\\mathcal{E}'=(e_1',e_2',\\ldots,e_n')\\) for \\(G\\) and \\(G'\\), respectively."
  },
  {
    "objectID": "topology/abelian-groups/index.html#matrix-of-a-homomorphism",
    "href": "topology/abelian-groups/index.html#matrix-of-a-homomorphism",
    "title": "Finitely-Generated Free Abelian Groups",
    "section": "Matrix of A Homomorphism",
    "text": "Matrix of A Homomorphism\nA homomorphism \\(F:G\\to G'\\) is a linear function, i.e., \\(F(x+y)=F(x)+F(y)\\) for all \\(x,y\\in G\\).\nAs a consequence, \\(F\\) is uniquely determined by its values on the elements of \\(\\mathcal{E}\\). For each \\(1\\leq j\\leq m\\), the image \\(F(e_j)\\) can be written uniquely as a (formal) linear combination of the elements of \\(\\mathcal{E}'\\). Let \\[\nF(e_j) = \\sum\\limits_{i=1}^{n} a_{ij}e_i'.\n\\]\nThe matrix \\(A:=\\{a_{ij}\\}\\in\\mathcal{M}_{n,m}(\\mathbb Z)\\) is called the matrix of \\(F\\) w.r.t. the (ordered) bases \\(\\mathcal{E},\\mathcal{E}'\\), and is denoted by \\([F]_{\\mathcal{E},\\mathcal{E'}}\\). In matrix notation, we have \\[\n\\bigg[F(e_1),\\ldots,F(e_j),\\ldots,F(e_m)\\bigg]=\n\\bigg[e_1',\\ldots,e_i',\\ldots,e_n'\\bigg]\n\\begin{bmatrix}\na_{11} & \\ldots & a_{1j} & \\ldots & a_{1m} \\\\\n\\ldots & \\ldots & \\ldots & \\ldots & \\ldots \\\\\na_{i1} & \\ldots & a_{ij} & \\ldots & a_{im} \\\\\n\\ldots & \\ldots & \\ldots & \\ldots & \\ldots \\\\\na_{n1} & \\ldots & a_{nj} & \\ldots & a_{nm} \\\\\n\\end{bmatrix}.\n\\] Tolerating a mild abuse of notation, we can also express the above relation as \\(F(\\mathcal{E})=\\mathcal{E'}[F]_{\\mathcal{E},\\mathcal{E'}}\\).\n\nExample:\nLet \\(F:\\mathbb{Z}^3\\to \\mathbb{Z}^2\\) be a homomorphism defined by \\[F(a,b,c)=(3a+4b-2c,2b+5c).\\]\nA natural choice of ordered bases is \\(\\mathcal{E}=\\bigg((1,0,0),(0,1,0),(0,0,1)\\bigg)\\) and \\(\\mathcal{E}'=\\bigg((1,0),(0,1)\\bigg)\\). In order to compute \\([F]_{\\mathcal{E},\\mathcal{E}''}\\), the matrix of \\(F\\) w.r.t. the chosen bases, we note that \\[\n\\begin{aligned}\nF(1,0,0) &= (3,0) = 3(1,0) + 0(0,1) \\\\\nF(0,1,0) &= (4,2) = 4(1,0) + 2(0,1) \\\\\nF(0,0,1) &= (-2,5) = -2(1,0) + 5(0,1)\n\\end{aligned}\n\\] So, the matrix of \\(F\\) is \\[\n\\begin{bmatrix}\n3 & 4 & -2\\\\\n0 & 2 & 5\n\\end{bmatrix}.\n\\]\nQuestion What would the matrix of \\(F\\) be if we chose the bases \\(\\bigg((1,1,0),(1,0,1),(0,1,1)\\bigg)\\) and \\(\\bigg((1,0),(1,1)\\bigg)\\)?\n\nFollowing the technique (basically the definition) of the above example we can compute the matrix of \\(F\\) under the new set of bases."
  },
  {
    "objectID": "topology/abelian-groups/index.html#change-of-basis",
    "href": "topology/abelian-groups/index.html#change-of-basis",
    "title": "Finitely-Generated Free Abelian Groups",
    "section": "Change of Basis",
    "text": "Change of Basis\nLet \\(\\mathcal{B}=(e_1,e_2,\\ldots,e_m)\\) be an ordered basis of a finitely-generated free abelian group \\(G\\). Now we consider an new basis \\(\\mathcal{C}=(f_1,f_2,\\ldots,f_m)\\) of \\(G\\). The basechange matrix encodes the change the basis from (old) \\(\\mathcal{B}\\) to (new) \\(\\mathcal{C}\\). The basechange matrix facilitates the computation of the matrix of a homomomorphism w.r.t. a set of new bases.\nThe starting point is to write the elements of the new basis as a linear combination of those of the old basis. For \\(j=1,2,\\ldots,m'\\), \\[\nf_j = \\sum\\limits_{i=1}^{m} p_{ij}e_i.\n\\]\nThe matrix \\(P\\) is called the basechange matrix the order bases \\(\\mathcal{B}\\text{ and }\\mathcal{C}\\). In matrix notation, \\[\\mathcal{C}=\\mathcal{B}P.\\]\nAs we can immediately see, the basechange matrix is unique, and it is also invertible [artin], i.e., \\(P\\in GL_{m}(\\mathbb Z)\\). Given an invertible, integer matrix, one can also use the above matrix relation to compute the new basis.\n\nExample:\nFor this example, I let you interact with the tutorial. We choose the dimension of \\(G\\) using the following slider. Upon choosing a value, you readily see the initial basis:\n\ntex`\\mathcal{B}=${nf.vec2Tex(B)}`\n\n\n\n\n\n\nand randomly generated basechange matrix \\(P\\).\n\nviewof m = Inputs.range([1, 6], {\n  value: 3,\n  step: 1,\n  label: \"Dimension (m):\"\n})\n\n\n\n\n\n\nNow, we take a random invertible matrix of the chosen dimension:\n\ntex.block`P=${nf.mat2Tex(P)}.`\n\n\n\n\n\n\nThe new basis of \\(G\\) is:\n\ntex.block`\\mathcal{C}=${nf.vec2Tex(nf.changeBasis(B,P))}.`\n\n\n\n\n\n\n\n\nApplication to Homomorphisms\nLet \\(F:G\\to G'\\) be a homomorphism. Let \\(A\\) denote the matrix of \\(F\\) w.r.t. a pair of old ordered bases \\((\\mathcal{B},\\mathcal{B}')\\) for \\(G\\) and \\(G'\\), respectively. If a new pair of order bases \\((\\mathcal{C},\\mathcal{C}')\\) chosen, one would be interested to compute the matrix of \\(F\\) w.r.t. the new bases.\nLet \\(P\\in\\mathcal{M}_m(\\mathbb Z)\\) and \\(Q\\in\\mathcal{M}_n(\\mathbb Z)\\) denote the basechange matrices for \\(G\\) and \\(G'\\), respectively. So, \\[\\mathcal{C}=\\mathcal{B}P\\text{, and }\\mathcal{C}'=\\mathcal{B}'Q.\\]\nBy the definition of \\(A\\), note that \\(F(\\mathcal{B})=\\mathcal{B}'A\\). Therefore, \\[\n\\begin{aligned}\nF(\\mathcal{B})P &=(\\mathcal{B}'A)P \\\\\n&= (\\mathcal{C}'Q^{-1})AP \\\\\n&= \\mathcal{C}'(Q^{-1}AP)\n\\end{aligned}\n\\]\nUsing the fact that \\(F\\) is a homomomorphism and letting \\(\\mathcal{B}=(e_1,e_2,\\ldots,e_m)\\) and \\(\\mathcal{C}=(f_1,f_2,\\ldots,f_m)\\), we simplify the LHS. \\[\n\\begin{aligned}\nF(\\mathcal{B})P &= \\big[F(e_1),\\ldots,F(e_j),\\ldots,F(e_m)\\big]P \\\\\n&= \\left[\\sum_{j=1}^mF(e_j)p_{1j},\\ldots,\\sum_{j=1}^mF(e_j)p_{mj}\\right] \\\\\n&= \\left[F\\left(\\sum_{j=1}^m p_{1j}e_j\\right),\\ldots,F\\left(\\sum_{j=1}^m p_{1j}e_j\\right)\\right] \\\\\n&= \\left[F\\left(f_1\\right),\\ldots,F\\left(f_m\\right)\\right] \\\\\n&= F(\\mathcal{C}).\n\\end{aligned}\n\\]\nTherefore, \\[F(\\mathcal{C})=\\mathcal{C}'\\left(Q^{-1}AP\\right).\\]\nWe conclude that \\(\\left(Q^{-1}AP\\right)\\) is the matrix of \\(F\\) w.r.t. the new pair of basis \\((\\mathcal{C},\\mathcal{C}')\\).\n\nnf = require(\"https://bundle.run/@tdajs/normal-form@2.1.0\")\nB = d3.range(0, m).map((e) => \"e_\" + (e + 1))\nP = {\n  let P = [];\n  do {\n    P = d3.range(0, m).map((row) => {\n      return d3.range(0, m).map((elm) => d3.randomInt(-5, 5)());\n    });\n  } while (new nf.NormalForm(P).D.includes(0));\n\n  return P;\n}"
  },
  {
    "objectID": "topology/reduction-action.html",
    "href": "topology/reduction-action.html",
    "title": "Reduction in Action",
    "section": "",
    "text": "For more details, see: Normal Form.\n\n\nCode\ndelay = 300\n\nA = {\n  let rows = 7; //d3.randomInt(1, 10)();\n  let cols = 7; //d3.randomInt(1, 10)();\n\n  return d3.range(0, rows).map((row) => {\n    return d3.range(0, cols).map((elm) => d3.randomInt(-3, 3)());\n  });\n}\n\nnf = require(\"https://bundle.run/@tdajs/normal-form@2.0.0\")\n\nsteps = new nf.NormalForm(A, {\n  recordSteps: true\n}).steps"
  },
  {
    "objectID": "miscellaneous/lorenz.html",
    "href": "miscellaneous/lorenz.html",
    "title": "Lorenz System",
    "section": "",
    "text": "Lorenz system is a system of (non-linear) ordinary differential equations.\n\\[\\begin{aligned}\n\\dot{x} &= \\sigma(y-x)\\\\\n\\dot{y} &= x(\\rho-z)-y\\\\\n\\dot{z} &= xy-\\beta z\n\\end{aligned}\\]\nHere \\(\\sigma,\\rho,\\text{ and }\\beta\\) are system parameters."
  },
  {
    "objectID": "miscellaneous/lorenz.html#evolution-projected-on-y-z-plane",
    "href": "miscellaneous/lorenz.html#evolution-projected-on-y-z-plane",
    "title": "Lorenz System",
    "section": "Evolution Projected on Y-Z Plane",
    "text": "Evolution Projected on Y-Z Plane\n\nPlot.plot({\n  height: 500,\n  widht: 500,\n  x: {\n    domain: [-30, 30],\n    grid: true\n  },\n  y: {\n    domain: [0, 50],\n    grid: true\n  },\n  marks: [\n    Plot.line(lorenzData.slice(0, n), {\n      x: \"y\",\n      y: \"z\",\n      strokeWidth: 0.5,\n      stroke: \"red\"\n    }),\n    Plot.ruleX([0]),\n    Plot.ruleY([0])\n  ]\n})"
  },
  {
    "objectID": "miscellaneous/lorenz.html#time-series-from-the-z-axis",
    "href": "miscellaneous/lorenz.html#time-series-from-the-z-axis",
    "title": "Lorenz System",
    "section": "Time-series from the Z-axis",
    "text": "Time-series from the Z-axis\n\nPlot.plot({\n  x: {\n    domain: [0, 4000]\n  },\n  marks: [\n    Plot.line(lorenzData.slice(0, n), {\n      x: \"n\",\n      y: \"z\"\n    }),\n    Plot.ruleX([1500, 3500], { stroke: \"red\" }),\n    Plot.ruleY([0])\n  ]\n})"
  },
  {
    "objectID": "miscellaneous/lorenz.html#takens-embedding",
    "href": "miscellaneous/lorenz.html#takens-embedding",
    "title": "Lorenz System",
    "section": "Takens’ Embedding",
    "text": "Takens’ Embedding\n\nviewof delay = Inputs.number({ value: 7, label: tex`Delay\\ (\\tau)` })\nPlot.plot({\n  marks: [\n    Plot.dot(\n      delayTS(\n        lorenzData.map((d) => d.x),\n        delay\n      ).slice(0, n),\n      {\n        stroke: \"red\",\n        r: 1\n      }\n    )\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndelayTS = function (ts, delay = 1, dim = 2) {\n  return ts.map((d, i) => {\n    const out = [];\n    for (let j = 0; j < dim; j++) out.push(ts[i + j * delay]);\n    return out;\n  });\n}\n\nlorenz = function (\n  [x, y, z] = [0, 0, 0],\n  n = 100,\n  { sigma = 10, r = 28, b = 8 / 3 } = {}\n) {\n  let F = function (t, [x, y, z]) {\n    return [sigma * (y - x), r * x - x * z - y, x * y - b * z];\n  };\n\n  let s = new odex.Solver(3);\n  let flow = [];\n\n  for (let i = 0; i < n; i++) {\n    [x, y, z] = s.solve(F, 0, [x, y, z], 0.01).y;\n    flow.push({ n: i, x: x, y: y, z: z });\n  }\n  return flow;\n}\n\nlorenzData = lorenz([1, 1, 1], 4000)\n\nodex = import(\"https://cdn.skypack.dev/odex\");\n\nn = {\n  let i = 0;\n  while (i < 4000) {\n    yield Promises.delay(10, ++i);\n  }\n}"
  },
  {
    "objectID": "data-science/order-statistics.html",
    "href": "data-science/order-statistics.html",
    "title": "Order Statistics",
    "section": "",
    "text": "In statistics, a one-value summary of a random sample is called a statistic. Mean, standard deviation, median, min, max of a sample are some of the commonly used statistics. While the computation of mean and standard deviation use the actual sample values—min, max, and median are computed using only their relative positions or order. When a sample is sorted in non-decreasing order, the first and the last positions are the min and the max, and the middle position is the median. The notion of order statistics generalizes such summaries of a sample.\nSince this is the most prevalent use case, we always consider a random sample \\(X_1, X_2,\\ldots, X_n\\) to be i.i.d. from a continuous random variable \\(X\\) following a common probability distribution \\(\\mathbb F(x)=\\mathbb P(X\\leq x)\\). The ordered sample is denoted by \\(X_{(1)}\\leq X_{(2)}\\leq\\ldots\\leq X_{(n)}\\), and \\(X_{(k)}\\) is called the \\(k\\)th-order statistic for any \\(1\\leq k\\leq n\\).\nSo, the \\(1\\)st and the \\(n\\)th order statistics are simply the sample min and smaple max, respectively. Moreover, \\(X_{\\left(\\frac{n-1}{2}\\right)}\\) is the sample median if \\(n\\) is odd.\nBefore exploring the sampling distributions of the order statistics in full generality, we start playing around with two very special order statistics—min and max."
  },
  {
    "objectID": "data-science/order-statistics.html#experimenting-with-the-extrema",
    "href": "data-science/order-statistics.html#experimenting-with-the-extrema",
    "title": "Order Statistics",
    "section": "Experimenting with the Extrema",
    "text": "Experimenting with the Extrema\nLet us consider a random sample of size \\(n=10\\) from the uniform distribution over the interval \\([0,1]\\). The sampled data-points are shown in Figure 1, along with the min (in green) and max (in red).\n\nPlot.plot({\n  height: 70,\n  x: { domain: [0,1] } ,\n  y: { ticks: 0 },\n  marks: [\n    Plot.ruleY([0], { stroke: 'lightgray' }),\n    Plot.dot({ length: 10 }, {\n      y: Array.from({ length: 10 }).fill(0),\n      x: d3.sort(Array.from({ length: 10 }, d3.randomUniform()) ),\n      fill: (d, i) => {\n        if(i===0)\n          return 'green'\n        if(i===9)\n          return 'red'\n        else\n          return 'lightgray'\n      }\n    })\n  ]\n})\n\n\n\n\n\nFigure 1: A random sample of size \\(10\\) from \\(\\mathrm{unif}([0,1])\\). The red and blue points denote the min and the max, respectively.\n\n\n\nIn this random instance of the sample, the sample min (equivalently max) is not very far from \\(0\\) (equaivalently \\(1\\)). We wonder if this is generally the case across random instances. It would definitely be counter-intuitive if it turns out that way. In our setup, each sample point \\(X_i\\) takes on a value in \\([0,1]\\), without any unfair bias in favor of a particular point—moreover, \\(X_i\\) is oblivious to the other draws \\(X_j\\) for \\(i\\neq j\\). So, it is most natural to think any point in the interval is equally-likely to be the min and max. In order to put this intuition to test, we take \\(m=5\\) random samples. Each sample is drawn on a line as before, and the samples are stacked vertically in Figure 2.\n\nPlot.plot({\n  height: 250,\n  marginLeft: 50,\n  x: { label: null, domain: [0,1]},\n  y: { label: null, tickRotate: 30, line: true, grid: true },\n  marks: [\n    Plot.dot( rUnif(5, 10), {\n      x: 'X', \n      y: (d) => \"sample \" + d.sample ,\n      fill: (d) => {\n        if(d.k === 1)\n          return 'green'\n        if(d.k === 10)\n          return 'red'\n        else\n          return 'lightgray'\n      }\n    })\n  ]\n});\n\n\n\n\n\nFigure 2: Samples are drawn on the horizontal lines, the red minimums and maximums are again shown in green and red.\n\n\n\nAs it turns out, sample mean \\(U\\) has a tendency to remain to close \\(0\\) and sample max \\(V\\) has a tendency to remain to close \\(1\\)! More specifically, for a sample of size \\(n\\) from uniform \\([0,1]\\) we have \\[E[U]=\\frac{1}{n+1}\\text{ and }E[V]=\\frac{n}{n+1}.\\]"
  },
  {
    "objectID": "data-science/order-statistics.html#probability-distributions-of-the-extrema",
    "href": "data-science/order-statistics.html#probability-distributions-of-the-extrema",
    "title": "Order Statistics",
    "section": "Probability Distributions of the Extrema",
    "text": "Probability Distributions of the Extrema\nLet us try to prove a little more general result. We compute now the density of the extrema \\(U\\) and \\(V\\) of a sample from a general probability distribution.\n\nTheorem 1 (Density Function of \\(V\\)) \nIf \\(X_1, X_2, \\ldots, X_n\\) are independent random variables with the common CDF \\(F\\) and density \\(f\\), then the density of \\(V\\) is \\[f_V(v)=nf(v)[F(v)]^{n-1}.\\]\n\n\nSolution. We first compute the CDF \\(F_V(v)\\) of \\(V\\), then differentiate it to get the PDF. In order to compute \\(F_V(v)\\), we note that \\(V\\leq v\\) if and only if every \\(X_i\\leq v\\). So, \\[\\begin{align}\nF_V(v) &=\\mathbb P(V\\leq v) \\\\\n&=\\mathbb P(X_1\\leq v, X_2\\leq v, \\ldots, X_n\\leq v) \\\\\n&=\\mathbb P(X_1\\leq v)\\mathbb P(X_2\\leq v)\\ldots\\mathbb P(X_n\\leq v) \\\\\n&=[F(v)]^n.\n\\end{align}\\] Differentiating we get the density \\[\n\\begin{align}\nf_V(v) &=\\frac{d}{dv}[F(v)]^n \\\\\n&=n[F(v)]^{n-1}\\frac{dF(v)}{dv} \\\\\n&=n[F(v)]^{n-1}f(v).\n\\end{align}\n\\]\n\n\nExercise 1 \nProve that, under the conditions of Theorem 1, the density of \\(U\\) is \\[f_U(u)=nf(u)[1-F(u)]^{n-1}.\\]"
  },
  {
    "objectID": "data-science/order-statistics.html#the-order-statistics-of-uniform-01",
    "href": "data-science/order-statistics.html#the-order-statistics-of-uniform-01",
    "title": "Order Statistics",
    "section": "The Order Statistics of Uniform \\([0,1]\\)",
    "text": "The Order Statistics of Uniform \\([0,1]\\)\nWe can now apply the density obtained in Theorem 2 to compute the expectations of the order statistics for a sample of size \\(n\\) from uniform \\([0,1]\\). In this case, \\[\nf(x)=\\begin{cases}\n1,&0\\leq x\\leq 1 \\\\\n0,&\\text{ otherwise}\n\\end{cases}\n\\] And, \\[\nF(x)=\\begin{cases}\n0,&x<0 \\\\\nx,&0\\leq x\\leq 1\\\\\n1,&x>1\n\\end{cases}\n\\] As a result, the density of the \\(k\\)th-order statistic is \\[\nf_k(x)=\\begin{cases}\n\\frac{n!}{(k-1)!(n-k)!}x^{k-1}(1-x)^{n-k},& 0\\leq x\\leq 1 \\\\\n0,&\\text{ otherwise}\n\\end{cases}\n\\] The expectation is \\[\n\\begin{align}\nE[X_{(k)}] &=\\int_0^1x\\cdot\\frac{n!}{(k-1)!(n-k)!}x^{k-1}(1-x)^{n-k}dx \\\\\n&=\\frac{n!}{(k-1)!(n-k)!}\\int_0^1x^k(1-x)^{n-k}dx.\n\\end{align}\n\\] The form of the integral is known as the Beta function. Using its relation to binomial coefficients, we can then write \\[\n\\begin{align}\nE[X_{(k)}]\n&=\\frac{n!}{(k-1)!(n-k)!}\\int_0^1x^k(1-x)^{n-k}dx \\\\\n&=\\frac{n!}{(k-1)!(n-k)!}\\cdot\\frac{k!(n-k)!}{(k+n-k+1)!} \\\\\n&=\\frac{k}{n+1}.\n\\end{align}\n\\] The typical positions of random draws (when sorted) are equally spaced over \\([0,1]\\) as evident in the following plot.\n\nviewof n = slider({ \n          min: 0,\n          max: 200,\n          step: 1, \n          label: `n` \n});\nviewof m = slider({     min: 0,\n          max: 200,step: 1, label: tex`m` });\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd = rUnif(m, n);\nPlot.plot({\n  y: { grid: true },\n  marks: [\n  Plot.dot(d,{ x: 'X', y: 'sample', fill: 'k'})\n  //Plot.ruleX(Array.from({ length: n }, (d, k) => ({ k: k+1, x: (k+1)/(n+1) })),     //{ x: 'x', stroke: 'k' })\n  ]\n});"
  },
  {
    "objectID": "data-science/qq.html",
    "href": "data-science/qq.html",
    "title": "Quantile-Quantile Plots",
    "section": "",
    "text": "Quantile-Quantile plot (also known as Q-Q plot) is an extremely useful visual tool for exploratory data analysis (EDA). A Q-Q plot is not particularly a summary of data, rather an informal assessment of goodness of fit to discern the disparity of two distributions. Quantiles from one distribution (usually from data) is plotted against those of another distribution (usually a theoretical, known model). For more examples and discussions, see (Wilk and Gnanadesikan 1968)."
  },
  {
    "objectID": "data-science/qq.html#theoretical-quantiles",
    "href": "data-science/qq.html#theoretical-quantiles",
    "title": "Quantile-Quantile Plots",
    "section": "Theoretical Quantiles",
    "text": "Theoretical Quantiles\n\nDefinition 1 (Theoretical Quantiles) \nFor any \\(p\\in[0,1]\\), a \\(p\\)th quantile of a random variable \\(X\\) is defined to be that value \\(x_p\\in\\mathbb R\\) such that \\(\\mathbb P(X\\leq x_p)=p\\).\n\nIn other words, the probability that \\(X\\) realizes a value not greater than a \\(p\\)th quantile is \\(p\\). For \\(p=\\frac{1}{2}\\), \\(x_p\\) is commonly known as median of \\(X\\). If \\(F(x)\\) denotes the CDF of \\(X\\), one notes that \\(x_p=F^{-1}(p)\\), provided the CDF \\(F(x)\\) is invertible1 near \\(x_p\\).\n\n\n\n\n\n\nQuantiles are not unique\n\n\n\nIn general, quantiles are not unique. Easy examples can be found when \\(X\\) is discrete. For an example on the continuous side, take \\(X\\sim\\mathrm{unif}([0,1])\\) to see that any number not less than \\(1\\) is a \\(p\\)th quantile for \\(p=1\\). See the CDF of \\(X\\) below to convince yourself.\n\n\n\nPlot.plot({\ngrid: true,\ny: {  ticks: 5 },\nx: { ticks: 3 },\nstyle: { fontSize: '1.2rem' },\nmarks: [\nPlot.line([[-1, 0],[0, 0]], { stroke: 'steelblue', strokeWidth: 3 }),\nPlot.line([[0, 1],[1, 1]], { stroke: 'steelblue', strokeWidth: 3 }),\nPlot.line([[1, 0],[2, 0]], { stroke: 'steelblue', strokeWidth: 3 }),\n]\n})\nPlot.line([[-1, 0],[0, 0],[1, 1], [2, 1]], { stroke: 'steelblue', strokeWidth: 3 }).plot({\ngrid: true,\ny: {  ticks: 5 },\nx: { ticks: 3 },\nstyle: { fontSize: '1.4rem' }\n})\n\n\n\n\n\n\n\n\n(a) PDF\n\n\n\n\n\n\n\n(b) CDF\n\n\n\nFigure 1: The density (left) and cumulative distribution (right) functions of uniform \\([0,1]\\) are shown by the blue lines. The CDF is only invertible on the support.\n\n\n\nMoving forward, we assume that the \\(X\\) is a continuous random variables and that its CDF \\(F\\) is a strictly increasing, continuous function, at least on an interval of the real line. As a consequence, the CDF is invertible everywhere and the \\(p\\)th quantile \\(x_p=F^{-1}(p)\\) is uniquely defined. Examples of such distributions include the exponential, \\(\\chi^2\\)- and F-distribution on \\((0,\\infty)\\), normal and Student’s t-distribution on \\(\\mathbb R\\), the Beta distribution on \\((0,1)\\), etc.\n\nExercise 1 \nFind a continuous distribution with the expected value \\(0\\) and whose CDF is only intertible on a bounded interval of the real line."
  },
  {
    "objectID": "data-science/qq.html#observed-quantiles",
    "href": "data-science/qq.html#observed-quantiles",
    "title": "Quantile-Quantile Plots",
    "section": "Observed Quantiles",
    "text": "Observed Quantiles\nWhile the quantiles of a probability distribution can be concretely defined (Definition 1), there have been quite a few conventions for the assignment of quantiles for a batch of observations or a dataset. Although, for a large sample they make little to no difference for a descriptive analysis. We use the following convention:\nFor a random sample \\(X_1, X_2, \\ldots, X_n\\) of size \\(n\\), the order statistics are denoted by \\(X_{(1)}\\leq X_{(2)}\\leq\\ldots\\leq X_{(n)}\\). And, the \\(k/(n+1)\\) quantile of data is assigned to \\(X_{(k)}\\), the \\(k\\)th-order statistic."
  },
  {
    "objectID": "data-science/qq.html#observed-vs-theoretical-quantiles",
    "href": "data-science/qq.html#observed-vs-theoretical-quantiles",
    "title": "Quantile-Quantile Plots",
    "section": "Observed vs Theoretical Quantiles",
    "text": "Observed vs Theoretical Quantiles\nLet us consider a sample of \\(n\\) from a uniform distribution from \\([0,1]\\). As proved in\n\nTesting Uniform Random Generator\n\nviewof n = Inputs.range([30,100],{ step: 1, label: 'sample size' })\nPlot.plot({\n  style: {  },\n  grid: true,\n  x: { label: `uniform quantiles →`, line: true },\n  y: { label: `↑ observed quantiles`, line: true },\n  marks: [\n    Plot.link({length: 1}, {\n      x1: 0,\n      x2: 1,\n      y1: 0,\n      y2: 1,\n    }),\n    Plot.dot({length: n}, {\n      x: d3.range(n).map(i => (i+1)/(n+1)),\n      y: d3.sort( Array.from({length: n}, d3.randomUniform()) )\n    }),\n  ]\n})"
  },
  {
    "objectID": "data-science/qq.html#two-observed-batches",
    "href": "data-science/qq.html#two-observed-batches",
    "title": "Quantile-Quantile Plots",
    "section": "Two Observed Batches",
    "text": "Two Observed Batches\n\ndata = await FileAttachment('Bjerkdahl.csv').csv({ typed: true });\ndataA = data.filter( d => d.Treatment === 'III' ).map( d => d.X ).sort( (a, b) => a - b);\ndataB = data.filter( d => d.Treatment === 'V' ).map( d => d.X ).sort( (a, b) => a - b);\nPlot.plot({\n  x: {\n    label: 'Quantiles of Group A'\n  },\n  y: {\n    label: 'Quantiles of Group B'\n  },\n  width: 500,\n  marks: [\n    Plot.dot(dataB.map( (q, i) => [ q, dataA[i] ] ), { fill: 'steelblue' }),\n    Plot.ruleX([0]),\n    Plot.ruleY([0]),\n    Plot.line([[0,0], [500, 500]], { stroke: 'gray' })\n  ], \n})"
  }
]